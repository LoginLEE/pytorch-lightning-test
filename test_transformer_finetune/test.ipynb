{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "colab,id,colab_type,-all",
      "formats": "ipynb,py:percent",
      "main_language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 609.342631,
      "end_time": "2021-06-28T10:15:28.840089",
      "environment_variables": {},
      "exception": null,
      "input_path": "lightning_examples/text-transformers/text-transformers.ipynb",
      "output_path": ".notebooks/lightning_examples/text-transformers.ipynb",
      "parameters": {},
      "start_time": "2021-06-28T10:05:19.497458",
      "version": "2.3.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "name": "text-transformers.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit ('pytorch-lightning': conda)"
    },
    "interpreter": {
      "hash": "5861b03558c0de50c2cea0c1516286ad159fda00e09ed3d31e5b219814ed16af"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Finetune Transformers Models with PyTorch Lightning\n",
        "\n",
        "* **Author:** PL team\n",
        "* **License:** CC BY-SA\n",
        "* **Generated:** 2021-06-28T09:27:48.748750\n",
        "\n",
        "This notebook will use HuggingFace's `datasets` library to get data, which will be wrapped in a `LightningDataModule`.\n",
        "Then, we write a class to perform text classification on any dataset from the [GLUE Benchmark](https://gluebenchmark.com/).\n",
        "(We just show CoLA and MRPC due to constraint on compute/disk)\n",
        "\n",
        "\n",
        "---\n",
        "Open in [![Open In Colab](https://colab.research.google.com/assets/colab-badge.png){height=\"20px\" width=\"117px\"}](https://colab.research.google.com/github/PytorchLightning/lightning-tutorials/blob/publication/.notebooks/lightning_examples/text-transformers.ipynb)\n",
        "\n",
        "Give us a ⭐ [on Github](https://www.github.com/PytorchLightning/pytorch-lightning/)\n",
        "| Check out [the documentation](https://pytorch-lightning.readthedocs.io/en/latest/)\n",
        "| Join us [on Slack](https://join.slack.com/t/pytorch-lightning/shared_invite/zt-pw5v393p-qRaDgEk24~EjiZNBpSQFgQ)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.009088,
          "end_time": "2021-06-28T10:05:20.506078",
          "exception": false,
          "start_time": "2021-06-28T10:05:20.496990",
          "status": "completed"
        },
        "tags": [],
        "id": "db10dc89"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "from datetime import datetime\n",
        "from typing import Optional\n",
        "\n",
        "import datasets\n",
        "import torch\n",
        "from pytorch_lightning import LightningDataModule, LightningModule, seed_everything, Trainer\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "AVAIL_GPUS = min(1, torch.cuda.device_count())"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T10:05:23.259715Z",
          "iopub.status.busy": "2021-06-28T10:05:23.259255Z",
          "iopub.status.idle": "2021-06-28T10:05:25.103440Z",
          "shell.execute_reply": "2021-06-28T10:05:25.102937Z"
        },
        "papermill": {
          "duration": 1.855638,
          "end_time": "2021-06-28T10:05:25.103557",
          "exception": false,
          "start_time": "2021-06-28T10:05:23.247919",
          "status": "completed"
        },
        "tags": [],
        "id": "4e20d9da",
        "outputId": "569c255b-54e8-43eb-fcb2-4b43557ec0b7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training BERT with Lightning"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.008081,
          "end_time": "2021-06-28T10:05:25.120279",
          "exception": false,
          "start_time": "2021-06-28T10:05:25.112198",
          "status": "completed"
        },
        "tags": [],
        "id": "2aea1548"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lightning DataModule for GLUE"
      ],
      "metadata": {
        "lines_to_next_cell": 2,
        "papermill": {
          "duration": 0.007795,
          "end_time": "2021-06-28T10:05:25.135828",
          "exception": false,
          "start_time": "2021-06-28T10:05:25.128033",
          "status": "completed"
        },
        "tags": [],
        "id": "a73df439"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "class GLUEDataModule(LightningDataModule):\n",
        "\n",
        "    task_text_field_map = {\n",
        "        'cola': ['sentence'],\n",
        "        'sst2': ['sentence'],\n",
        "        'mrpc': ['sentence1', 'sentence2'],\n",
        "        'qqp': ['question1', 'question2'],\n",
        "        'stsb': ['sentence1', 'sentence2'],\n",
        "        'mnli': ['premise', 'hypothesis'],\n",
        "        'qnli': ['question', 'sentence'],\n",
        "        'rte': ['sentence1', 'sentence2'],\n",
        "        'wnli': ['sentence1', 'sentence2'],\n",
        "        'ax': ['premise', 'hypothesis']\n",
        "    }\n",
        "\n",
        "    glue_task_num_labels = {\n",
        "        'cola': 2,\n",
        "        'sst2': 2,\n",
        "        'mrpc': 2,\n",
        "        'qqp': 2,\n",
        "        'stsb': 1,\n",
        "        'mnli': 3,\n",
        "        'qnli': 2,\n",
        "        'rte': 2,\n",
        "        'wnli': 2,\n",
        "        'ax': 3\n",
        "    }\n",
        "\n",
        "    loader_columns = [\n",
        "        'datasets_idx', 'input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions',\n",
        "        'labels'\n",
        "    ]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name_or_path: str,\n",
        "        task_name: str = 'mrpc',\n",
        "        max_seq_length: int = 128,\n",
        "        train_batch_size: int = 32,\n",
        "        eval_batch_size: int = 32,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.model_name_or_path = model_name_or_path\n",
        "        self.task_name = task_name\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.train_batch_size = train_batch_size\n",
        "        self.eval_batch_size = eval_batch_size\n",
        "\n",
        "        self.text_fields = self.task_text_field_map[task_name]\n",
        "        self.num_labels = self.glue_task_num_labels[task_name]\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path, use_fast=True)\n",
        "\n",
        "    def setup(self, stage: str):\n",
        "        self.dataset = datasets.load_dataset('glue', self.task_name)\n",
        "\n",
        "        for split in self.dataset.keys():\n",
        "            self.dataset[split] = self.dataset[split].map(\n",
        "                self.convert_to_features,\n",
        "                batched=True,\n",
        "                remove_columns=['label'],\n",
        "            )\n",
        "            self.columns = [c for c in self.dataset[split].column_names if c in self.loader_columns]\n",
        "            self.dataset[split].set_format(type=\"torch\", columns=self.columns)\n",
        "\n",
        "        self.eval_splits = [x for x in self.dataset.keys() if 'validation' in x]\n",
        "\n",
        "    def prepare_data(self):\n",
        "        datasets.load_dataset('glue', self.task_name)\n",
        "        AutoTokenizer.from_pretrained(self.model_name_or_path, use_fast=True)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.dataset['train'], batch_size=self.train_batch_size)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        if len(self.eval_splits) == 1:\n",
        "            return DataLoader(self.dataset['validation'], batch_size=self.eval_batch_size)\n",
        "        elif len(self.eval_splits) > 1:\n",
        "            return [DataLoader(self.dataset[x], batch_size=self.eval_batch_size) for x in self.eval_splits]\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        if len(self.eval_splits) == 1:\n",
        "            return DataLoader(self.dataset['test'], batch_size=self.eval_batch_size)\n",
        "        elif len(self.eval_splits) > 1:\n",
        "            return [DataLoader(self.dataset[x], batch_size=self.eval_batch_size) for x in self.eval_splits]\n",
        "\n",
        "    def convert_to_features(self, example_batch, indices=None):\n",
        "\n",
        "        # Either encode single sentence or sentence pairs\n",
        "        if len(self.text_fields) > 1:\n",
        "            texts_or_text_pairs = list(\n",
        "                zip(example_batch[self.text_fields[0]], example_batch[self.text_fields[1]])\n",
        "            )\n",
        "        else:\n",
        "            texts_or_text_pairs = example_batch[self.text_fields[0]]\n",
        "\n",
        "        # Tokenize the text/text pairs\n",
        "        features = self.tokenizer.batch_encode_plus(\n",
        "            texts_or_text_pairs, max_length=self.max_seq_length, pad_to_max_length=True, truncation=True\n",
        "        )\n",
        "\n",
        "        # Rename label to labels to make it easier to pass to model forward\n",
        "        features['labels'] = example_batch['label']\n",
        "\n",
        "        return features"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T10:05:25.164524Z",
          "iopub.status.busy": "2021-06-28T10:05:25.159117Z",
          "iopub.status.idle": "2021-06-28T10:05:25.166615Z",
          "shell.execute_reply": "2021-06-28T10:05:25.166147Z"
        },
        "papermill": {
          "duration": 0.023056,
          "end_time": "2021-06-28T10:05:25.166724",
          "exception": false,
          "start_time": "2021-06-28T10:05:25.143668",
          "status": "completed"
        },
        "tags": [],
        "id": "b434024a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You could use this datamodule with standalone PyTorch if you wanted...**"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.008151,
          "end_time": "2021-06-28T10:05:25.183113",
          "exception": false,
          "start_time": "2021-06-28T10:05:25.174962",
          "status": "completed"
        },
        "tags": [],
        "id": "f70cc76c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "dm = GLUEDataModule('distilbert-base-uncased')\n",
        "dm.prepare_data()\n",
        "dm.setup('fit')\n",
        "next(iter(dm.train_dataloader()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset glue (/home/edmundlylee/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "Reusing dataset glue (/home/edmundlylee/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "Loading cached processed dataset at /home/edmundlylee/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-9e81c8360baad98a.arrow\n",
            "  0%|          | 0/1 [00:00<?, ?ba/s]/home/edmundlylee/anaconda3/envs/pytorch-lightning/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2184: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [00:00<00:00, 60.31ba/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 35.47ba/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " 'input_ids': tensor([[  101,  2572,  3217,  ...,     0,     0,     0],\n",
              "         [  101,  9805,  3540,  ...,     0,     0,     0],\n",
              "         [  101,  2027,  2018,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  101,  1996,  2922,  ...,     0,     0,     0],\n",
              "         [  101,  6202,  1999,  ...,     0,     0,     0],\n",
              "         [  101, 16565,  2566,  ...,     0,     0,     0]]),\n",
              " 'labels': tensor([1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
              "         1, 1, 0, 0, 1, 1, 1, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T10:05:25.202441Z",
          "iopub.status.busy": "2021-06-28T10:05:25.201985Z",
          "iopub.status.idle": "2021-06-28T10:05:42.150545Z",
          "shell.execute_reply": "2021-06-28T10:05:42.150123Z"
        },
        "papermill": {
          "duration": 16.959598,
          "end_time": "2021-06-28T10:05:42.150660",
          "exception": false,
          "start_time": "2021-06-28T10:05:25.191062",
          "status": "completed"
        },
        "tags": [],
        "id": "8f4532d0",
        "outputId": "3e5d31df-7a89-4cf7-adf0-0195f221c488",
        "colab": {
          "referenced_widgets": [
            "731915bdb83e4a0b91565b843b2b77ff",
            "de5b417ffcb34a8f8c89bfbf366aa1ca",
            "db7b7d94178c4231a1fd38a023b01a58",
            "b6000a8aee5c486e9a5a816c15955d99",
            "36651ed76422457ca6ecc9c518b1590a",
            "e0bca5b93d764bb7a29b9b99ea55a025",
            "dc6048cc31174cc19d97fe42296e68dd",
            "38a965b72c70465ca9097fad649ce492",
            "1590b505994c449fa9542cca4d6d1dda",
            "a8a8cddff979490b907d0622f5a0df0e",
            "4917267e228e45d9accd3b71e1727999",
            "625f1d1c4519443baca34a4e28c036ec",
            "a892d1cb0ec0407dbb1bfb6981723ad3",
            "b368ce8bc4e64faf85e68ac042da6303",
            "2567af30a8a844249de8d805f0532682"
          ]
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer LightningModule"
      ],
      "metadata": {
        "lines_to_next_cell": 2,
        "papermill": {
          "duration": 0.016489,
          "end_time": "2021-06-28T10:05:42.185157",
          "exception": false,
          "start_time": "2021-06-28T10:05:42.168668",
          "status": "completed"
        },
        "tags": [],
        "id": "51393799"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "class GLUETransformer(LightningModule):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name_or_path: str,\n",
        "        num_labels: int,\n",
        "        task_name: str,\n",
        "        learning_rate: float = 2e-5,\n",
        "        adam_epsilon: float = 1e-8,\n",
        "        warmup_steps: int = 0,\n",
        "        weight_decay: float = 0.0,\n",
        "        train_batch_size: int = 32,\n",
        "        eval_batch_size: int = 32,\n",
        "        eval_splits: Optional[list] = None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.config = AutoConfig.from_pretrained(model_name_or_path, num_labels=num_labels)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            model_name_or_path, config=self.config\n",
        "        )\n",
        "        self.metric = datasets.load_metric(\n",
        "            'glue', self.hparams.task_name, experiment_id=datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
        "        )\n",
        "\n",
        "    def forward(self, **inputs):\n",
        "        return self.model(**inputs)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        outputs = self(**batch)\n",
        "        loss = outputs[0]\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        outputs = self(**batch)\n",
        "        val_loss, logits = outputs[:2]\n",
        "\n",
        "        if self.hparams.num_labels >= 1:\n",
        "            preds = torch.argmax(logits, axis=1)\n",
        "        elif self.hparams.num_labels == 1:\n",
        "            preds = logits.squeeze()\n",
        "\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        return {'loss': val_loss, \"preds\": preds, \"labels\": labels}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        if self.hparams.task_name == 'mnli':\n",
        "            for i, output in enumerate(outputs):\n",
        "                # matched or mismatched\n",
        "                split = self.hparams.eval_splits[i].split('_')[-1]\n",
        "                preds = torch.cat([x['preds'] for x in output]).detach().cpu().numpy()\n",
        "                labels = torch.cat([x['labels'] for x in output]).detach().cpu().numpy()\n",
        "                loss = torch.stack([x['loss'] for x in output]).mean()\n",
        "                self.log(f'val_loss_{split}', loss, prog_bar=True)\n",
        "                split_metrics = {\n",
        "                    f\"{k}_{split}\": v\n",
        "                    for k, v in self.metric.compute(predictions=preds, references=labels).items()\n",
        "                }\n",
        "                self.log_dict(split_metrics, prog_bar=True)\n",
        "            return loss\n",
        "\n",
        "        preds = torch.cat([x['preds'] for x in outputs]).detach().cpu().numpy()\n",
        "        labels = torch.cat([x['labels'] for x in outputs]).detach().cpu().numpy()\n",
        "        loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log_dict(self.metric.compute(predictions=preds, references=labels), prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def setup(self, stage=None) -> None:\n",
        "        if stage != 'fit':\n",
        "            return\n",
        "        # Get dataloader by calling it - train_dataloader() is called after setup() by default\n",
        "        train_loader = self.train_dataloader()\n",
        "\n",
        "        # Calculate total steps\n",
        "        tb_size = self.hparams.train_batch_size * max(1, self.trainer.gpus)\n",
        "        ab_size = self.trainer.accumulate_grad_batches * float(self.trainer.max_epochs)\n",
        "        self.total_steps = (len(train_loader.dataset) // tb_size) // ab_size\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Prepare optimizer and schedule (linear warmup and decay)\"\"\"\n",
        "        model = self.model\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": self.hparams.weight_decay,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },\n",
        "        ]\n",
        "        optimizer = AdamW(\n",
        "            optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon\n",
        "        )\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=self.hparams.warmup_steps,\n",
        "            num_training_steps=self.total_steps,\n",
        "        )\n",
        "        scheduler = {'scheduler': scheduler, 'interval': 'step', 'frequency': 1}\n",
        "        return [optimizer], [scheduler]"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T10:05:42.232982Z",
          "iopub.status.busy": "2021-06-28T10:05:42.232474Z",
          "iopub.status.idle": "2021-06-28T10:05:42.234600Z",
          "shell.execute_reply": "2021-06-28T10:05:42.234139Z"
        },
        "papermill": {
          "duration": 0.032703,
          "end_time": "2021-06-28T10:05:42.234704",
          "exception": false,
          "start_time": "2021-06-28T10:05:42.202001",
          "status": "completed"
        },
        "tags": [],
        "id": "21cd92db"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.016046,
          "end_time": "2021-06-28T10:05:42.267291",
          "exception": false,
          "start_time": "2021-06-28T10:05:42.251245",
          "status": "completed"
        },
        "tags": [],
        "id": "1f92aa78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CoLA\n",
        "\n",
        "See an interactive view of the\n",
        "CoLA dataset in [NLP Viewer](https://huggingface.co/nlp/viewer/?dataset=glue&config=cola)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.016124,
          "end_time": "2021-06-28T10:05:42.299618",
          "exception": false,
          "start_time": "2021-06-28T10:05:42.283494",
          "status": "completed"
        },
        "tags": [],
        "id": "687d515f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "seed_everything(42)\n",
        "\n",
        "dm = GLUEDataModule(model_name_or_path='albert-base-v2', task_name='cola')\n",
        "dm.setup('fit')\n",
        "model = GLUETransformer(\n",
        "    model_name_or_path='albert-base-v2',\n",
        "    num_labels=dm.num_labels,\n",
        "    eval_splits=dm.eval_splits,\n",
        "    task_name=dm.task_name,\n",
        ")\n",
        "\n",
        "trainer = Trainer(max_epochs=3, gpus=AVAIL_GPUS)\n",
        "trainer.fit(model, dm)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n",
            "Reusing dataset glue (/home/edmundlylee/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "100%|██████████| 9/9 [00:00<00:00, 41.15ba/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 58.86ba/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 53.88ba/s]\n",
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.dense.weight']\n",
            "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "Reusing dataset glue (/home/edmundlylee/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "/home/edmundlylee/anaconda3/envs/pytorch-lightning/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  rank_zero_deprecation(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                            | Params\n",
            "----------------------------------------------------------\n",
            "0 | model | AlbertForSequenceClassification | 11.7 M\n",
            "----------------------------------------------------------\n",
            "11.7 M    Trainable params\n",
            "0         Non-trainable params\n",
            "11.7 M    Total params\n",
            "46.740    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/edmundlylee/anaconda3/envs/pytorch-lightning/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                      "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/edmundlylee/anaconda3/envs/pytorch-lightning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
            "Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 1/301 [00:00<00:28, 10.67it/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/edmundlylee/anaconda3/envs/pytorch-lightning/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:   0%|          | 0/301 [00:00<00:00, 2228.64it/s, loss=0.62, v_num=0, val_loss=0.608, matthews_correlation=0.000] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/edmundlylee/anaconda3/envs/pytorch-lightning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:   0%|          | 0/301 [00:00<00:00, 1833.98it/s, loss=0.614, v_num=0, val_loss=0.608, matthews_correlation=0.000] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/edmundlylee/anaconda3/envs/pytorch-lightning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: 100%|██████████| 301/301 [00:44<00:00,  6.81it/s, loss=0.614, v_num=0, val_loss=0.608, matthews_correlation=0.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/edmundlylee/anaconda3/envs/pytorch-lightning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ]
        }
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T10:05:42.336066Z",
          "iopub.status.busy": "2021-06-28T10:05:42.335602Z",
          "iopub.status.idle": "2021-06-28T10:12:14.519312Z",
          "shell.execute_reply": "2021-06-28T10:12:14.518896Z"
        },
        "papermill": {
          "duration": 392.203489,
          "end_time": "2021-06-28T10:12:14.519468",
          "exception": false,
          "start_time": "2021-06-28T10:05:42.315979",
          "status": "completed"
        },
        "tags": [],
        "id": "0639ce2c",
        "outputId": "0b7123c3-0619-47d8-9b14-5c4dcf0f7875",
        "colab": {
          "referenced_widgets": [
            "4bbf99260f7f4d20aeeae0f178222419",
            "249dd7c3354648efa2c65e17e94b2a8a",
            "a418767a076f4a58ac59a1424e4be05a",
            "61476a0dd56d4bd2a4eec93fec0c9b29",
            "373c35afc8e94fb6974809e7f150a886",
            "e8ea39d0c71441358575a351f1d9c2aa",
            "817e28dbecda4e7080adebdf8fa32435",
            "38053fb7b03e4b71aed5076f9c5273a6",
            "312b9bba77914da7b8d6a8e6bd642ffc",
            "d0892b844bfa44e0b4dee9cb8cd9ba56",
            "7fe0f15ea9b44524ad364cddc60376e5",
            "daaaf84b5e644c6b826063c99c53dee2",
            "3e6c01f420f94557b81bf4e9b5864451",
            "f9ed8b8f9cb44eae98b820f631c42e42",
            "17ede62eb4f9485d805431c445def3fd",
            "2f97bc9964904d39a22921f7aef5d9ad",
            "6ee37a8d53784640987b2bbd533bacea"
          ]
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MRPC\n",
        "\n",
        "See an interactive view of the\n",
        "MRPC dataset in [NLP Viewer](https://huggingface.co/nlp/viewer/?dataset=glue&config=mrpc)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.026691,
          "end_time": "2021-06-28T10:12:14.573432",
          "exception": false,
          "start_time": "2021-06-28T10:12:14.546741",
          "status": "completed"
        },
        "tags": [],
        "id": "ee1aebd1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "seed_everything(42)\n",
        "\n",
        "dm = GLUEDataModule(\n",
        "    model_name_or_path='distilbert-base-cased',\n",
        "    task_name='mrpc',\n",
        ")\n",
        "dm.setup('fit')\n",
        "model = GLUETransformer(\n",
        "    model_name_or_path='distilbert-base-cased',\n",
        "    num_labels=dm.num_labels,\n",
        "    eval_splits=dm.eval_splits,\n",
        "    task_name=dm.task_name\n",
        ")\n",
        "\n",
        "trainer = Trainer(max_epochs=3, gpus=AVAIL_GPUS)\n",
        "trainer.fit(model, dm)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n",
            "Downloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 30.9kB/s]\n",
            "Downloading: 100%|██████████| 411/411 [00:00<00:00, 316kB/s]\n",
            "Downloading: 100%|██████████| 213k/213k [00:00<00:00, 540kB/s]\n",
            "Downloading: 100%|██████████| 436k/436k [00:00<00:00, 1.06MB/s]\n",
            "Reusing dataset glue (/home/edmundlylee/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "  0%|          | 0/4 [00:00<?, ?ba/s]/home/edmundlylee/anaconda3/envs/pytorch-lightning/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2184: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "100%|██████████| 4/4 [00:00<00:00, 36.94ba/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 61.51ba/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 39.06ba/s]\n",
            "Downloading: 100%|██████████| 263M/263M [00:22<00:00, 11.5MB/s]\n",
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "Reusing dataset glue (/home/edmundlylee/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "/home/edmundlylee/anaconda3/envs/pytorch-lightning/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  rank_zero_deprecation(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                                | Params\n",
            "--------------------------------------------------------------\n",
            "0 | model | DistilBertForSequenceClassification | 65.8 M\n",
            "--------------------------------------------------------------\n",
            "65.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "65.8 M    Total params\n",
            "263.132   Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                              "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/edmundlylee/anaconda3/envs/pytorch-lightning/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 0/128 [00:00<00:00, 3075.00it/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/edmundlylee/anaconda3/envs/pytorch-lightning/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: 100%|██████████| 128/128 [00:09<00:00, 13.28it/s, loss=0.61, v_num=1, val_loss=0.614, accuracy=0.684, f1=0.812]\n"
          ]
        }
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T10:12:14.631076Z",
          "iopub.status.busy": "2021-06-28T10:12:14.630582Z",
          "iopub.status.idle": "2021-06-28T10:13:49.640318Z",
          "shell.execute_reply": "2021-06-28T10:13:49.640706Z"
        },
        "papermill": {
          "duration": 95.040747,
          "end_time": "2021-06-28T10:13:49.640857",
          "exception": false,
          "start_time": "2021-06-28T10:12:14.600110",
          "status": "completed"
        },
        "tags": [],
        "id": "d4a95c91",
        "outputId": "9b60bd38-1be4-4e41-b4fc-c3494c15750f",
        "colab": {
          "referenced_widgets": [
            "a2d34b7c998c46f5b139266cd45780b8",
            "c19513fa17964a8a853f64e7412f5c11",
            "f7be7b575cd44fd4b82b20dc56287c6e",
            "0d80ae2bb4a64d728bcc30885d1934b0",
            "b22143e919b64855a68a046b553ee0ea",
            "cce75dd570374d97b54f20edbacab6e6",
            "4e279a93c91549afaa78506a24051dd8",
            "6355a9f7ef3b48f9a8bc5122b6153ab7",
            "46179daf3a02450a9fd3bd360e6a744d",
            "c090cb50040444c3946deb3bb9d2bae3",
            "f176149b114b49c8a53ea7be987a647b",
            "3c0c0b5c4cbc4780bc6088ffd445cdaf",
            "42969135a0aa452f9dca55e772e5eadb"
          ]
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MNLI\n",
        "\n",
        " - The MNLI dataset is huge, so we aren't going to bother trying to train on it here.\n",
        " - We will skip over training and go straight to validation.\n",
        "\n",
        "See an interactive view of the\n",
        "MRPC dataset in [NLP Viewer](https://huggingface.co/nlp/viewer/?dataset=glue&config=mnli)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.03555,
          "end_time": "2021-06-28T10:13:49.712405",
          "exception": false,
          "start_time": "2021-06-28T10:13:49.676855",
          "status": "completed"
        },
        "tags": [],
        "id": "1e6f2b73"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "dm = GLUEDataModule(\n",
        "    model_name_or_path='distilbert-base-cased',\n",
        "    task_name='mnli',\n",
        ")\n",
        "dm.setup('fit')\n",
        "model = GLUETransformer(\n",
        "    model_name_or_path='distilbert-base-cased',\n",
        "    num_labels=dm.num_labels,\n",
        "    eval_splits=dm.eval_splits,\n",
        "    task_name=dm.task_name\n",
        ")\n",
        "\n",
        "trainer = Trainer(gpus=AVAIL_GPUS, progress_bar_refresh_rate=20)\n",
        "trainer.validate(model, dm.val_dataloader())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset glue/mnli (download: 298.29 MiB, generated: 78.65 MiB, post-processed: Unknown size, total: 376.95 MiB) to /home/edmundlylee/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: 100%|██████████| 313M/313M [00:34<00:00, 9.17MB/s]\n",
            "  0%|          | 0/393 [00:00<?, ?ba/s]/home/edmundlylee/anaconda3/envs/pytorch-lightning/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2184: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "  1%|          | 3/393 [00:00<00:18, 20.80ba/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset glue downloaded and prepared to /home/edmundlylee/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 393/393 [00:10<00:00, 36.33ba/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 40.68ba/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 32.63ba/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 43.74ba/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 41.65ba/s]\n",
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating:   0%|          | 0/615 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/edmundlylee/anaconda3/envs/pytorch-lightning/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "/home/edmundlylee/anaconda3/envs/pytorch-lightning/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 1, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating: 100%|██████████| 615/615 [00:12<00:00, 47.43it/s]--------------------------------------------------------------------------------\n",
            "DATALOADER:0 VALIDATE RESULTS\n",
            "{'accuracy_matched': 0.32399389147758484,\n",
            " 'accuracy_mismatched': 0.3184499740600586,\n",
            " 'val_loss_matched': 1.104953408241272,\n",
            " 'val_loss_mismatched': 1.1044032573699951}\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:1 VALIDATE RESULTS\n",
            "{'accuracy_matched': 0.32399389147758484,\n",
            " 'accuracy_mismatched': 0.3184499740600586,\n",
            " 'val_loss_matched': 1.104953408241272,\n",
            " 'val_loss_mismatched': 1.1044032573699951}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'val_loss_matched': 1.104953408241272,\n",
              "  'accuracy_matched': 0.32399389147758484,\n",
              "  'val_loss_mismatched': 1.1044032573699951,\n",
              "  'accuracy_mismatched': 0.3184499740600586},\n",
              " {'val_loss_matched': 1.104953408241272,\n",
              "  'accuracy_matched': 0.32399389147758484,\n",
              "  'val_loss_mismatched': 1.1044032573699951,\n",
              "  'accuracy_mismatched': 0.3184499740600586}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T10:13:49.789879Z",
          "iopub.status.busy": "2021-06-28T10:13:49.789403Z",
          "iopub.status.idle": "2021-06-28T10:15:27.894620Z",
          "shell.execute_reply": "2021-06-28T10:15:27.894148Z"
        },
        "papermill": {
          "duration": 98.146783,
          "end_time": "2021-06-28T10:15:27.894740",
          "exception": false,
          "start_time": "2021-06-28T10:13:49.747957",
          "status": "completed"
        },
        "tags": [],
        "id": "99a7f89d",
        "outputId": "9e7ccd6e-a007-42f2-e2c9-017176b0d9e4",
        "colab": {
          "referenced_widgets": [
            "6923f86e82684c70a9fead7c6c7bf7e1",
            "aaa66c924ea44d9a9e601797a8590ab4",
            "3dfc9b575b254560a15a84298d5fbc69",
            "84ea422750b048e6a76cc870823e1683",
            "466ccfe2504e476f869553b657cc48ec",
            "d711739117c8401aa605c1f2ea82d231",
            "7d4bbdc077c34f9dbe1daa3c3308023c",
            "8eacd977b7264996b35746fd5598530b",
            "ed6a7c7aa2f34dd483a2a6a19c5f15a7",
            "158f15db4afa433c90e2f2f3f92388c1",
            "ddaf611d1eba4116b8ed19ba72626e06",
            "77627e73cfb940d6b06bd245ff2731ea"
          ]
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# Start tensorboard.\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs/"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6008 (pid 101745), started 0:00:59 ago. (Use '!kill 101745' to kill it.)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-bdd640fb06671ad1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-bdd640fb06671ad1\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6008;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ]
}